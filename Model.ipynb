{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the project\n",
    "\n",
    "The goal of the project is to have a Arduino take and process an image taken from the camera of the arduino, then image to send to the laptop for a NN to identify the digit that it was given to it\n",
    "\n",
    "## How will this be achived?\n",
    "Firstly, I will use Pytorch, A well known Machine learning library to make and train the model. Then using pygame and make a simple Paint2D interface for the users to draw their digit. Then with Pyserial I will use a serial connection to the arduino to indicate which class the AI thinks it is and then output it on the LEDs for the user to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can get the MNIST dataset from the torchvision class and import toTensor so they become Pytorch Tensors\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "Data = datasets.MNIST(root=\"data\", download=False, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the data we need to start training the model.\n",
    "\n",
    "But first we should split the data into Training (70%), Testing(20%) and Validation(10%) Sets to ensure good learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "TRAINING_SIZE   = int(len(Data) * 0.7)\n",
    "TESTING_SIZE    = int(len(Data) * 0.2)\n",
    "VALIDATION_SIZE = int(len(Data) * 0.1)\n",
    "\n",
    "TrainingData, TestingData, ValidationData = random_split(Data, [TRAINING_SIZE, TESTING_SIZE, VALIDATION_SIZE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put them in a Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "TrainLoader      = DataLoader(TrainingData,   batch_size=BATCH_SIZE, shuffle=True)\n",
    "TestingLoader    = DataLoader(TestingData,    batch_size=BATCH_SIZE, shuffle=True)\n",
    "ValidationLoader = DataLoader(ValidationData, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything ready and can start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Model Architecture\n",
    "class NumberIdentifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Identifier = nn.Sequential(\n",
    "            # Our Input Features are 28 x 28 so 784 \n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10) # We have 10 digits to identify from 0 -> 9 so we have ten output classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten x so it isn't a 28 x 28 and a 1D 784 image\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.Identifier(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return torch.argmax(self.Identifier(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built our model it has 4 total layers(Two being hidden layers) and all layers have the ReLU activation function.\n",
    "\n",
    "Now lets train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "ImageClassifier = NumberIdentifier() # Unfortunetly we don't have a GPU so we can't speed it up\n",
    "Optimizer       = Adam(ImageClassifier.parameters(), lr=0.001)\n",
    "CostFunction    = nn.CrossEntropyLoss()\n",
    "Scheduler       = ExponentialLR(Optimizer, gamma=0.8) # To prevent overfitting the model we will use this to exponentially decrease the learning rate every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # Another library which just shows us % done of loops\n",
    "\n",
    "# Training Loop\n",
    "NUMEPOCHS = 4\n",
    "\n",
    "for i in range(NUMEPOCHS):\n",
    "    # Training Loop\n",
    "    ImageClassifier.train()\n",
    "    TrainingLoss     = 0\n",
    "    TrainingAccuracy = 0\n",
    "\n",
    "    for batch in tqdm(TrainLoader, desc=\"Training\"):\n",
    "        x, y = batch\n",
    "        \n",
    "        # Do the forwards pass on our model to find out the error\n",
    "        y_hat = ImageClassifier(x)\n",
    "\n",
    "        # Calculate the cost\n",
    "        Cost = CostFunction(y_hat, y)\n",
    "\n",
    "        # Backwards pass\n",
    "        Optimizer.zero_grad()\n",
    "        Cost.backward()\n",
    "        Optimizer.step()\n",
    "\n",
    "        # Record Loss and Accuracy\n",
    "        TrainingLoss += Cost.item()\n",
    "        TrainingAccuracy += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    TrainingAccuracy /= len(TrainLoader) * BATCH_SIZE\n",
    "    TrainingLoss     /= len(TrainLoader)\n",
    "\n",
    "    print(f\"Epoch {i + 1}/{NUMEPOCHS}, Avg. Training Loss: {(TrainingLoss / len(TrainLoader)):.4f}, Training Accuracy {TrainingAccuracy * 100}%\")\n",
    "\n",
    "    # For Validation loop it's pretty much the same\n",
    "    ImageClassifier.eval()\n",
    "    ValidationLoss     = 0\n",
    "    ValidationAccuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(ValidationLoader, desc=\"Validating\"):\n",
    "            x, y = batch\n",
    "\n",
    "            # Do the forwards pass on our model to find out the error\n",
    "            y_hat = ImageClassifier(x)\n",
    "\n",
    "            # Calculate the cost\n",
    "            ValidationCost = CostFunction(y_hat, y)\n",
    "\n",
    "            # Record loss and Accuracy\n",
    "            ValidationLoss += ValidationCost.item()\n",
    "            ValidationAccuracy += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    ValidationAccuracy /= len(ValidationLoader) * BATCH_SIZE\n",
    "    ValidationLoss     /= len(ValidationLoader)\n",
    "\n",
    "    print(f\"Epoch {i + 1}/{NUMEPOCHS}, Avg. Validation Loss: {(ValidationLoss):.4f}, Validation Accuracy { ValidationAccuracy * 100}%\")\n",
    "\n",
    "    # Adjust Learning Rate\n",
    "    Scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we trained the AI lets test it to see how well it performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 188/188 [00:01<00:00, 139.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Complete! Average Testing Loss: 0.0, Accuracy: 97.00797872340425%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostly the same thing with the validation loop\n",
    "ImageClassifier.eval()\n",
    "\n",
    "TestingLoss = 0\n",
    "CorrectPredictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    TestingAccuracy = 0\n",
    "    for batch in tqdm(TestingLoader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "\n",
    "        # Get the forward passes\n",
    "        y_hat = ImageClassifier(x)\n",
    "\n",
    "        # Calculate the cost\n",
    "        TestingLoss = CostFunction(y_hat, y)\n",
    "\n",
    "        # Record loss and Accuracy\n",
    "        TestingLoss += TestingLoss.item()\n",
    "        CorrectPredictions += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "CorrectPredictions /= len(TestingLoader) * BATCH_SIZE\n",
    "print(f\"\\n Testing Complete! Average Testing Loss: {(TestingAccuracy / len(TestingLoader))}, Accuracy: {CorrectPredictions * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets save the model so we don't have to Train it every time we run the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ImageClassifier.state_dict(), 'TrainedModel/ImageClassifier_97') # The Number at the end indicates its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model = torch.load('TrainedModel/ImageClassifier_97')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "TestingData    = iter(TestingLoader)\n",
    "Images, Labels = next(TestingData)\n",
    "\n",
    "Index = random.randint(0, BATCH_SIZE - 1)\n",
    "\n",
    "RandImage      = Images[Index]\n",
    "RandImageIndex = Labels[Index]\n",
    "\n",
    "Prediction = model.predict(RandImage)\n",
    "\n",
    "print(f\"The AI Prediction: {Prediction.item()}\")\n",
    "print(f\"Actual Class:      {RandImageIndex.item()}\")\n",
    "\n",
    "plt.imshow(RandImage.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
